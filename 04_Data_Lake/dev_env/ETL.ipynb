{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Imports Done ------\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "\n",
    "print('------ Imports Done ------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('data_lake.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_KEY']\n",
    "\n",
    "logs_bucket = config['S3']['LOG_DATA']\n",
    "songs_bucket = config['S3']['SONG_DATA']\n",
    "output_bucket = config['S3']['OUTPUT_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://85fd27796637:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f92128b15f8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the songs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|     artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARTC1LV1187B9A4858|        51.4536|Goldsmith's Colle...|        -0.01802|  The Bonzo Dog Band|301.40036|        1|SOAFBCP12A8C13CC7D|King Of Scurf (20...|1972|\n",
      "|ARA23XO1187B9AF18F|       40.57885|Carteret, New Jersey|       -74.21956|     The Smithereens|  192.522|        1|SOKTJDS12AF72A25E5|Drown In My Own T...|   0|\n",
      "|ARSVTNL1187B992A91|       51.50632|     London, England|        -0.12714|       Jonathan King|129.85424|        1|SOEKAZG12AB018837E|I'll Slap Your Fa...|2001|\n",
      "|AR73AIO1187B9AD57B|       37.77916|   San Francisco, CA|      -122.42005|   Western Addiction|118.07302|        1|SOQPWCR12A6D4FB2A3|A Poor Recipe For...|2005|\n",
      "|ARXQBR11187B98A2CC|           null|  Liverpool, England|            null|Frankie Goes To H...|821.05424|        1|SOBRKGM12A8C139EF6|Welcome to the Pl...|1985|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs = spark.read.json(f'{songs_bucket}/A/A/A/*.json')\n",
    "songs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.createOrReplaceTempView('tmp_songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOHOZBI12A8C132E3C|         Smash It Up|AR0MWD61187B9B2B12|2000|195.39546|\n",
      "|SOXZYWX12A6310ED0C|     It's About Time|ARC1IHZ1187FB4E920|   0| 246.9873|\n",
      "|SOHKNRJ12A6701D1F8|        Drop of Rain|AR10USD1187B99F3F1|   0|189.57016|\n",
      "|SOIGICF12A8C141BC5|        Game & Watch|AREWD471187FB49873|2004|580.54485|\n",
      "|SOAPERH12A58A787DC|The One And Only ...|ARZ5H0P1187B98A1DD|   0|230.42567|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table = spark.sql(\n",
    "    '''\n",
    "    SELECT DISTINCT song_id, title, artist_id, year, duration\n",
    "    FROM tmp_songs\n",
    "    WHERE song_id IS NOT NULL\n",
    "    ''')\n",
    "songs_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+-----------+--------+---------+\n",
      "|         artist_id|             name|   location|latitude|longitude|\n",
      "+------------------+-----------------+-----------+--------+---------+\n",
      "|ARJNIUY12298900C91|     Adelitas Way|           |    null|     null|\n",
      "|AR5LMPY1187FB573FE|Chaka Khan_ Rufus|Chicago, IL|41.88415|-87.63241|\n",
      "|AR1C2IX1187B99BF74|  Broken Spindles|           |    null|     null|\n",
      "|ARC1IHZ1187FB4E920|     Jamie Cullum|           |    null|     null|\n",
      "|ARKYKXP11F50C47A6A| The Supersuckers|           |    null|     null|\n",
      "+------------------+-----------------+-----------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_table = spark.sql(\n",
    "    '''\n",
    "    SELECT DISTINCT artist_id, artist_name AS name, artist_location AS location,\n",
    "                    artist_latitude AS latitude, artist_longitude AS longitude\n",
    "    FROM tmp_songs\n",
    "    WHERE artist_id IS NOT NULL\n",
    "    ''')\n",
    "artist_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with the events files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+--------------------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|           song|status|           ts|           userAgent|userId|          start_time|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+--------------------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|  Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|50841-09-12 03:26...|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|50841-09-19 17:23...|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|50841-09-22 17:36...|\n",
      "|       null|Logged In|    Wyatt|     M|            0|   Scott|     null| free|Eureka-Arcata-For...|   GET|    Home|1.540872073796E12|      563|           null|   200|1542247071796|Mozilla/5.0 (Wind...|     9|50841-11-11 20:23...|\n",
      "|       null|Logged In|   Austin|     M|            0| Rosales|     null| free|New York-Newark-J...|   GET|    Home|1.541059521796E12|      521|           null|   200|1542252577796|Mozilla/5.0 (Wind...|    12|50842-01-14 13:49...|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events = spark.read.json(f'{logs_bucket}/*/*/*.json')\n",
    "events = events.withColumn(\"start_time\",\n",
    "        (col(\"ts\")/1000).cast(\"timestamp\"))\n",
    "events.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.createOrReplaceTempView('tmp_events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+-----+-------+\n",
      "|          start_time|hour|day|week|month| year|weekday|\n",
      "+--------------------+----+---+----+-----+-----+-------+\n",
      "|50842-12-03 20:43...|  20|  3|  49|   12|50842|      4|\n",
      "|50843-07-21 13:46...|  13| 21|  30|    7|50843|      3|\n",
      "|50844-03-05 18:26...|  18|  5|   9|    3|50844|      7|\n",
      "|50859-03-07 10:56...|  10|  7|  10|    3|50859|      6|\n",
      "|50860-05-26 18:19...|  18| 26|  22|    5|50860|      4|\n",
      "+--------------------+----+---+----+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table = spark.sql(\n",
    "    '''\n",
    "    SELECT DISTINCT start_time,\n",
    "                    EXTRACT(hour from start_time) as hour,\n",
    "                    EXTRACT(day from start_time) as day,\n",
    "                    EXTRACT(week from start_time) as week,\n",
    "                    EXTRACT(month from start_time) as month,\n",
    "                    EXTRACT(year from start_time) as year,\n",
    "                    DAYOFWEEK(start_time) AS weekday\n",
    "    FROM tmp_events\n",
    "    WHERE ts IS NOT NULL\n",
    "    ''')\n",
    "time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     98|    Jordyn|   Powell|     F| free|\n",
      "|     34|    Evelin|    Ayala|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| paid|\n",
      "|     38|    Gianna|    Jones|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_table = spark.sql('''\n",
    "    SELECT DISTINCT userId as user_id, firstName as first_name, lastName as last_name, gender, level\n",
    "    FROM tmp_events\n",
    "    WHERE userId IS NOT NULL\n",
    "    ''')\n",
    "users_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+----------+--------+----------+-------+---------+\n",
      "|start_time|user_id|level|session_id|location|user_agent|song_id|artist_id|\n",
      "+----------+-------+-----+----------+--------+----------+-------+---------+\n",
      "+----------+-------+-----+----------+--------+----------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table = spark.sql(\n",
    "    '''\n",
    "    SELECT e.start_time, e.userId AS user_id, e.level, e.sessionId AS session_id, e.location,\n",
    "           e.userAgent AS user_agent, s.song_id, s.artist_id\n",
    "    FROM tmp_events e\n",
    "    JOIN tmp_songs s ON e.artist = s.artist_name\n",
    "    AND e.song = s.title\n",
    "    WHERE e.page = 'NextSong'\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}